{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46a22d7",
   "metadata": {},
   "source": [
    "# Problem Definition \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07331027",
   "metadata": {},
   "source": [
    "The goal is to build a system that can predict potential directories on a website based on its existing structure. This can be useful for web crawling, SEO analysis, and security assessments.\n",
    "\n",
    "The system will use one independent model trained to predict both; lateral and hierarchical directories.\n",
    "- Lateral discovery: It will identify top-level directories that are likely to be present on a similar website (e.g., `/about`, `/contact`).\n",
    "- Hierarchical discovery: It predicts subdirectories based on the parent directory (e.g., `/parent/child`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae09ec0",
   "metadata": {},
   "source": [
    "# Data Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d3cef",
   "metadata": {},
   "source": [
    "Origin of the dataset: [Common Crawl - Open Repository of Web Crawl Data](https://commoncrawl.org)\n",
    "\n",
    "Chosen subset for analysis: [Common Crawl Columnar URL Index Files](https://data.commoncrawl.org/cc-index/table/cc-main/warc/crawl=CC-MAIN-2025-38/subset=warc/part-00000-165bfb83-c006-44f2-a121-3d8ae730bc93.c000.gz.parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a063e",
   "metadata": {},
   "source": [
    "# Global Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91404e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388a415",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfd0e9",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d166e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/part-00000-802c11a9-bd5f-4d25-a78f-7a021d95d575.c000.gz.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc10fcb",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df2894",
   "metadata": {},
   "source": [
    "Simply print the shape of the dataframe to understand the number of records and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5412bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1235437</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rows  cols\n",
       "0  1235437    30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_shape = {\"rows\": [df.shape[0]], \"cols\": [df.shape[1]]}\n",
    "display(pd.DataFrame(data_shape))\n",
    "del data_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc74c2",
   "metadata": {},
   "source": [
    "### Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04e5da",
   "metadata": {},
   "source": [
    "Sample a few records to get a sense of the data structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca364430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_names</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url_surtkey</td>\n",
       "      <td>ro,ilfovsport)/tag/afumati-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>url</td>\n",
       "      <td>https://k-pop.rocks/artist/1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>url_host_name</td>\n",
       "      <td>george-dragon.ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>url_host_tld</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>url_host_2nd_last_part</td>\n",
       "      <td>bwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>url_host_3rd_last_part</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>url_host_4th_last_part</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>url_host_5th_last_part</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>url_host_registry_suffix</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>url_host_registered_domain</td>\n",
       "      <td>sanrotex.ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>url_host_private_suffix</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>url_host_private_domain</td>\n",
       "      <td>goodscents.ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>url_host_name_reversed</td>\n",
       "      <td>ro.complexcochet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>url_protocol</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>url_port</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>url_path</td>\n",
       "      <td>/246430676.phtml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>url_query</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fetch_time</td>\n",
       "      <td>2025-08-13 09:59:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fetch_status</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fetch_redirect</td>\n",
       "      <td>https://mktsolutions.ro/protectie/39-combinezoane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>content_digest</td>\n",
       "      <td>3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>content_mime_type</td>\n",
       "      <td>text/html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>content_mime_detected</td>\n",
       "      <td>text/html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>content_charset</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>content_languages</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>content_truncated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>warc_filename</td>\n",
       "      <td>crawl-data/CC-MAIN-2025-33/segments/1754151279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>warc_record_offset</td>\n",
       "      <td>12781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>warc_record_length</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>warc_segment</td>\n",
       "      <td>1754151577992.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     col_names  \\\n",
       "0                  url_surtkey   \n",
       "1                          url   \n",
       "2                url_host_name   \n",
       "3                 url_host_tld   \n",
       "4       url_host_2nd_last_part   \n",
       "5       url_host_3rd_last_part   \n",
       "6       url_host_4th_last_part   \n",
       "7       url_host_5th_last_part   \n",
       "8     url_host_registry_suffix   \n",
       "9   url_host_registered_domain   \n",
       "10     url_host_private_suffix   \n",
       "11     url_host_private_domain   \n",
       "12      url_host_name_reversed   \n",
       "13                url_protocol   \n",
       "14                    url_port   \n",
       "15                    url_path   \n",
       "16                   url_query   \n",
       "17                  fetch_time   \n",
       "18                fetch_status   \n",
       "19              fetch_redirect   \n",
       "20              content_digest   \n",
       "21           content_mime_type   \n",
       "22       content_mime_detected   \n",
       "23             content_charset   \n",
       "24           content_languages   \n",
       "25           content_truncated   \n",
       "26               warc_filename   \n",
       "27          warc_record_offset   \n",
       "28          warc_record_length   \n",
       "29                warc_segment   \n",
       "\n",
       "                                                 data  \n",
       "0                        ro,ilfovsport)/tag/afumati-2  \n",
       "1                     https://k-pop.rocks/artist/1517  \n",
       "2                                    george-dragon.ro  \n",
       "3                                                  ro  \n",
       "4                                               bwear  \n",
       "5                                                None  \n",
       "6                                                None  \n",
       "7                                                None  \n",
       "8                                                  ro  \n",
       "9                                         sanrotex.ro  \n",
       "10                                                 ro  \n",
       "11                                      goodscents.ro  \n",
       "12                                   ro.complexcochet  \n",
       "13                                              https  \n",
       "14                                                NaN  \n",
       "15                                   /246430676.phtml  \n",
       "16                                               None  \n",
       "17                          2025-08-13 09:59:10+00:00  \n",
       "18                                                301  \n",
       "19  https://mktsolutions.ro/protectie/39-combinezoane  \n",
       "20                   3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ  \n",
       "21                                          text/html  \n",
       "22                                          text/html  \n",
       "23                                               None  \n",
       "24                                               None  \n",
       "25                                               None  \n",
       "26  crawl-data/CC-MAIN-2025-33/segments/1754151279...  \n",
       "27                                           12781345  \n",
       "28                                               1971  \n",
       "29                                   1754151577992.76  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_data = {\n",
    "    \"col_names\": list(df.columns),\n",
    "    \"data\": [df[col].sample(n=1).iloc[0] for col in df.columns],\n",
    "}\n",
    "\n",
    "display(pd.DataFrame(sample_data))\n",
    "del sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdb460",
   "metadata": {},
   "source": [
    "Based on these observations, we will focus on the following columns for our analysis:\n",
    "- `url_path`: It contains the path component of the URL\n",
    "- `url_host_registered_domain`: It contains the registered domain of the URL\n",
    "- `fetch_status`: It indicates the HTTP status code of the URL fetch operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec07c2",
   "metadata": {},
   "source": [
    "## Identify Empty Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d40a05",
   "metadata": {},
   "source": [
    "Identify and handle any empty rows in the selected columns to ensure data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf189f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url_path</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url_host_registered_domain</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetch_status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NaN count\n",
       "url_path                            0\n",
       "url_host_registered_domain          0\n",
       "fetch_status                        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"url_path\", \"url_host_registered_domain\", \"fetch_status\"]\n",
    "\n",
    "nan_values = {}\n",
    "for column in columns:\n",
    "    nan_values[column] = df[column].isna().sum()\n",
    "\n",
    "display(pd.DataFrame.from_dict(nan_values, orient=\"index\", columns=[\"NaN count\"]))\n",
    "del nan_values, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce5eb1",
   "metadata": {},
   "source": [
    "## Check for Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abde4d9",
   "metadata": {},
   "source": [
    "Checking for duplicate entries in the selected columns to maintain data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3dfd61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct duplicated url_path values: 81718\n",
      "Top 10 duplicated url_path values and counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_path</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage_of_total_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/</td>\n",
       "      <td>68155</td>\n",
       "      <td>5.516671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/index.php</td>\n",
       "      <td>13075</td>\n",
       "      <td>1.058330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Catalogul-Bibliotecii-BNR-10393.aspx</td>\n",
       "      <td>3188</td>\n",
       "      <td>0.258046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/video/</td>\n",
       "      <td>2380</td>\n",
       "      <td>0.192644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ucp.php</td>\n",
       "      <td>2307</td>\n",
       "      <td>0.186736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/url</td>\n",
       "      <td>2232</td>\n",
       "      <td>0.180665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/drept/culegeri-de-jurisprudenta-si-legislatie</td>\n",
       "      <td>1920</td>\n",
       "      <td>0.155411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/e107_plugins/forum/forum_viewtopic.php</td>\n",
       "      <td>1708</td>\n",
       "      <td>0.138251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/advanced_search_result.php</td>\n",
       "      <td>1496</td>\n",
       "      <td>0.121091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/file.php</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.105469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         url_path  count  \\\n",
       "0                                               /  68155   \n",
       "1                                      /index.php  13075   \n",
       "2           /Catalogul-Bibliotecii-BNR-10393.aspx   3188   \n",
       "3                                         /video/   2380   \n",
       "4                                        /ucp.php   2307   \n",
       "5                                            /url   2232   \n",
       "6  /drept/culegeri-de-jurisprudenta-si-legislatie   1920   \n",
       "7         /e107_plugins/forum/forum_viewtopic.php   1708   \n",
       "8                     /advanced_search_result.php   1496   \n",
       "9                                       /file.php   1303   \n",
       "\n",
       "   percentage_of_total_rows  \n",
       "0                  5.516671  \n",
       "1                  1.058330  \n",
       "2                  0.258046  \n",
       "3                  0.192644  \n",
       "4                  0.186736  \n",
       "5                  0.180665  \n",
       "6                  0.155411  \n",
       "7                  0.138251  \n",
       "8                  0.121091  \n",
       "9                  0.105469  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dup_counts = df[\"url_path\"].value_counts()\n",
    "dup_only = dup_counts[dup_counts > 1].reset_index()\n",
    "dup_only.columns = [\"url_path\", \"count\"]\n",
    "dup_only[\"percentage_of_total_rows\"] = (dup_only[\"count\"] / len(df) * 100).round(6)\n",
    "\n",
    "print(f\"Number of distinct duplicated url_path values: {len(dup_only)}\")\n",
    "print(\"Top 10 duplicated url_path values and counts:\")\n",
    "display(dup_only.head(10))\n",
    "del dup_counts, dup_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80183d",
   "metadata": {},
   "source": [
    "## Path Depth Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0b043",
   "metadata": {},
   "source": [
    "Statistics on the depth of URL paths to understand the distribution of path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11b1fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.235437e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.592459e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.488754e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           url_path\n",
       "count  1.235437e+06\n",
       "mean   2.592459e+00\n",
       "std    1.488754e+00\n",
       "min    0.000000e+00\n",
       "25%    2.000000e+00\n",
       "50%    2.000000e+00\n",
       "75%    3.000000e+00\n",
       "max    3.200000e+01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depth_data = df[\"url_path\"].str.count(\"/\").describe()\n",
    "display(depth_data.to_frame())\n",
    "del depth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cacd0c",
   "metadata": {},
   "source": [
    "## Domain Frequency Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d3919",
   "metadata": {},
   "source": [
    "Understand the frequency distribution of registered domains in the dataset. This can help identify popular domains and potential biases in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c86d7725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique domains: 58265\n",
      "\n",
      "Top 20 domains by row count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_host_registered_domain</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32074</th>\n",
       "      <td>monitorulsv.ro</td>\n",
       "      <td>18433</td>\n",
       "      <td>1.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>carzz.ro</td>\n",
       "      <td>11932</td>\n",
       "      <td>0.9658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19364</th>\n",
       "      <td>gov.ro</td>\n",
       "      <td>11093</td>\n",
       "      <td>0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21465</th>\n",
       "      <td>hotnews.ro</td>\n",
       "      <td>7837</td>\n",
       "      <td>0.6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54048</th>\n",
       "      <td>ubbcluj.ro</td>\n",
       "      <td>7632</td>\n",
       "      <td>0.6178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>k-pop.rocks</td>\n",
       "      <td>7188</td>\n",
       "      <td>0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>dcmedical.ro</td>\n",
       "      <td>6993</td>\n",
       "      <td>0.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>digi24.ro</td>\n",
       "      <td>6541</td>\n",
       "      <td>0.5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19293</th>\n",
       "      <td>google.ro</td>\n",
       "      <td>5699</td>\n",
       "      <td>0.4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46720</th>\n",
       "      <td>sfatulmedicului.ro</td>\n",
       "      <td>5467</td>\n",
       "      <td>0.4425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30757</th>\n",
       "      <td>metalhead.ro</td>\n",
       "      <td>5158</td>\n",
       "      <td>0.4175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>bnr.ro</td>\n",
       "      <td>4539</td>\n",
       "      <td>0.3674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41466</th>\n",
       "      <td>radioiasi.ro</td>\n",
       "      <td>3780</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54826</th>\n",
       "      <td>uvt.ro</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26284</th>\n",
       "      <td>ladys.ro</td>\n",
       "      <td>3088</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14657</th>\n",
       "      <td>eventim.ro</td>\n",
       "      <td>2972</td>\n",
       "      <td>0.2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40352</th>\n",
       "      <td>profitshare.ro</td>\n",
       "      <td>2893</td>\n",
       "      <td>0.2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42999</th>\n",
       "      <td>reverse.ro</td>\n",
       "      <td>2840</td>\n",
       "      <td>0.2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34770</th>\n",
       "      <td>ofertelecatalog.ro</td>\n",
       "      <td>2717</td>\n",
       "      <td>0.2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12580</th>\n",
       "      <td>edu.ro</td>\n",
       "      <td>2683</td>\n",
       "      <td>0.2172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      url_host_registered_domain  count  percentage\n",
       "32074             monitorulsv.ro  18433      1.4920\n",
       "2665                    carzz.ro  11932      0.9658\n",
       "19364                     gov.ro  11093      0.8979\n",
       "21465                 hotnews.ro   7837      0.6344\n",
       "54048                 ubbcluj.ro   7632      0.6178\n",
       "25176                k-pop.rocks   7188      0.5818\n",
       "8947                dcmedical.ro   6993      0.5660\n",
       "10200                  digi24.ro   6541      0.5294\n",
       "19293                  google.ro   5699      0.4613\n",
       "46720         sfatulmedicului.ro   5467      0.4425\n",
       "30757               metalhead.ro   5158      0.4175\n",
       "359                       bnr.ro   4539      0.3674\n",
       "41466               radioiasi.ro   3780      0.3060\n",
       "54826                     uvt.ro   3292      0.2665\n",
       "26284                   ladys.ro   3088      0.2500\n",
       "14657                 eventim.ro   2972      0.2406\n",
       "40352             profitshare.ro   2893      0.2342\n",
       "42999                 reverse.ro   2840      0.2299\n",
       "34770         ofertelecatalog.ro   2717      0.2199\n",
       "12580                     edu.ro   2683      0.2172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_counts = (\n",
    "    df.groupby(\"url_host_registered_domain\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "domain_counts[\"percentage\"] = (domain_counts[\"count\"] / len(df) * 100).round(4)\n",
    "\n",
    "print(f\"Unique domains: {len(domain_counts)}\\n\")\n",
    "print(\"Top 20 domains by row count:\")\n",
    "\n",
    "display(domain_counts.head(20))\n",
    "\n",
    "del domain_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf426f59",
   "metadata": {},
   "source": [
    "## Status Code Frequency Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee091179",
   "metadata": {},
   "source": [
    "404 responses are particularly important as they indicate missing pages, which are irrelevant for our directory prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08301175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 status codes by row count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_code</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>534149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>397027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>179965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304</td>\n",
       "      <td>32526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>403</td>\n",
       "      <td>29355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>308</td>\n",
       "      <td>13048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>410</td>\n",
       "      <td>12605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>10957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>307</td>\n",
       "      <td>7412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>303</td>\n",
       "      <td>5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>503</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>401</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>429</td>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>406</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>504</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>502</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>520</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>522</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status_code   count\n",
       "0           301  534149\n",
       "1           404  397027\n",
       "2           302  179965\n",
       "3           304   32526\n",
       "4           403   29355\n",
       "5           308   13048\n",
       "6           410   12605\n",
       "7           500   10957\n",
       "8           307    7412\n",
       "9           303    5137\n",
       "10          503    3194\n",
       "11          401    2244\n",
       "12          429    1835\n",
       "13          406    1091\n",
       "14          504     810\n",
       "15          400     787\n",
       "16          502     625\n",
       "17          201     476\n",
       "18          520     368\n",
       "19          522     349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hola\n",
    "status_counts = df[\"fetch_status\"].value_counts().reset_index()\n",
    "status_counts.columns = [\"status_code\", \"count\"]\n",
    "print(\"Top 20 status codes by row count:\")\n",
    "display(status_counts.head(20))\n",
    "\n",
    "del status_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb5ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f3ffc",
   "metadata": {},
   "source": [
    "Things to consider:\n",
    "- Fortunately, any of the columns of interest does not contain any null values.\n",
    "- There are some duplicate entries in the `url_host_registered_domain` column.\n",
    "- The 75th percentile of the number of slashes (how deep the path is) is 3 which means that there are not many abnormally deep paths.\n",
    "- There are a significant number of paths that respond with 404 status code.\n",
    "\n",
    "Preprocessing steps based on the analysis above:\n",
    "\n",
    "1. Take valuable columns \n",
    "2. Randomize the dataset\n",
    "3. Normalize the paths by converting them to lowercase and stripping whitespace.\n",
    "4. Exclude paths that are too deep (e.g., more than 10 slashes) to avoid outliers.\n",
    "5. Remove rows with 404 status codes to focus on existing directories.\n",
    "6. Remove files and query parameters from the paths to focus on directory structures.\n",
    "7. Remove duplicate entries in the `url_path` column.\n",
    "8. Remove directory names that mostly contain non-alphabetic characters (e.g., `/12345`, `/!@#$%`), are too short (e.g., less than 3 characters), or are too long (e.g., more than 100 characters).\n",
    "9. For the `url_path` column, filter out rows with extremely deep paths (e.g., more than 10 slashes) to avoid outliers.\n",
    "10. Remove directory names that contain more than 6 digits to avoid noise from auto-generated directories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a11de88",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db8c03",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7efacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4528c",
   "metadata": {},
   "source": [
    "## Path Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db9f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/part-00000-802c11a9-bd5f-4d25-a78f-7a021d95d575.c000.gz.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "148e6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1235437, 30)\n"
     ]
    }
   ],
   "source": [
    "# Take valuable columns\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "df_clean = df[[\"url_host_registered_domain\", \"url_path\", \"fetch_status\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830a75c",
   "metadata": {},
   "source": [
    "Shuffling the dataset is done to ensure that the training and testing sets are representative of the overall data distribution. This helps in reducing bias and variance in the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebb2e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled: (1235437, 3)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataset\n",
    "df_clean = df_clean.sample(frac=1, random_state=1)\n",
    "print(f\"Shuffled: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f1fd7",
   "metadata": {},
   "source": [
    "Part of data normalization is to convert all paths to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e166990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To lowercase: (1235437, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert all paths to lowercase\n",
    "df_clean[\"url_path\"] = df_clean[\"url_path\"].str.lower()\n",
    "print(f\"To lowercase: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9650072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 removed: (838410, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove 404\n",
    "df_clean = df_clean[df_clean[\"fetch_status\"] != 404]\n",
    "print(f\"404 removed: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803243ec",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0ed0f",
   "metadata": {},
   "source": [
    "Most machine learning models require numerical input. Therefore, we need to convert the directory names into a numerical format that the model can understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a372600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the path by checking if it has the \"/\" character\n",
    "def validate_path(url):\n",
    "    return url if isinstance(url, str) and \"/\" in url else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b6e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra whitespeces and \"/\" characters at the end and start of the string\n",
    "def clean_slashes(url):\n",
    "    url = url.strip().strip(\"/\")\n",
    "\n",
    "    return url if url else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1227b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate directory names into a list\n",
    "def tokenize(url):\n",
    "    return url.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d8e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes using a pipeline\n",
    "def url_tokenize_pipeline(url):\n",
    "    url = validate_path(url)\n",
    "    if not url: return None\n",
    "\n",
    "    url = clean_slashes(url)\n",
    "    if not url: return None\n",
    "\n",
    "    return tokenize(url)\n",
    "\n",
    "df_clean[\"url_path\"] = df_clean[\"url_path\"].apply(url_tokenize_pipeline)\n",
    "df_clean = df_clean.dropna(subset=[\"url_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659ba564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized: (774661, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_host_registered_domain</th>\n",
       "      <th>url_path</th>\n",
       "      <th>fetch_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>bnr.ro</td>\n",
       "      <td>[catalogul-bibliotecii-bnr-10393.aspx]</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711011</th>\n",
       "      <td>nutriland.ro</td>\n",
       "      <td>[products, vit-min-powder-pudra-150g-ostrovit-...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825627</th>\n",
       "      <td>profismile.ro</td>\n",
       "      <td>[cnn1122368.htm]</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100122</th>\n",
       "      <td>tunetanken.ro</td>\n",
       "      <td>[categorie, agro, constructie-agro, produse-pe...</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834381</th>\n",
       "      <td>protv.ro</td>\n",
       "      <td>[emisiuni, 19-stirile-pro-tv, episodul, 41221-...</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        url_host_registered_domain  \\\n",
       "4220                        bnr.ro   \n",
       "711011                nutriland.ro   \n",
       "825627               profismile.ro   \n",
       "1100122              tunetanken.ro   \n",
       "834381                    protv.ro   \n",
       "\n",
       "                                                  url_path  fetch_status  \n",
       "4220                [catalogul-bibliotecii-bnr-10393.aspx]           302  \n",
       "711011   [products, vit-min-powder-pudra-150g-ostrovit-...           302  \n",
       "825627                                    [cnn1122368.htm]           301  \n",
       "1100122  [categorie, agro, constructie-agro, produse-pe...           503  \n",
       "834381   [emisiuni, 19-stirile-pro-tv, episodul, 41221-...           403  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display sample of the data\n",
    "print(f\"Tokenized: {df_clean.shape}\")\n",
    "display(df_clean.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a994b0",
   "metadata": {},
   "source": [
    "## Local Token Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13091fe",
   "metadata": {},
   "source": [
    "Filtering data is relevant to the model's focus on directory names. By removing irrelevant tokens, we can improve the model's performance and reduce noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d2512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep directory names using valid characters\n",
    "def is_allowed_char(c):\n",
    "    return c.isalnum() or c in \"-_%\"\n",
    "\n",
    "def filter_allowed_chars(tokens):\n",
    "    return [d for d in tokens if all(is_allowed_char(c) for c in d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7c15b",
   "metadata": {},
   "source": [
    "Long directory names are likely to be less common. Examples include session IDs or unique identifiers that do not generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad17ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove long direcotory names\n",
    "def filter_length(tokens, max_len=15):\n",
    "    return [d for d in tokens if len(d) <= max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf298a85",
   "metadata": {},
   "source": [
    "Similary, tokens with a high digit count are often not meaningful directory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d0bc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove directory names that mostly contain digits\n",
    "def is_mostly_digits(s, threshold=0.5):\n",
    "    digit_count = sum(c.isdigit() for c in s)\n",
    "    return (digit_count / len(s)) >= threshold\n",
    "\n",
    "def filter_digits(tokens):\n",
    "    return [\n",
    "        d for d in tokens \n",
    "        if not (d.isdigit() and len(d) > 6) and not (is_mostly_digits(d) and len(d) > 10)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebc4d1",
   "metadata": {},
   "source": [
    "Deep directory paths can introduce noise and complexity to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "991efdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit paths that are too deep\n",
    "def limit_depth(tokens, max_depth=10):\n",
    "    return tokens[:max_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcb40c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes using a pipeline\n",
    "def token_filter_pipeline(tokens):\n",
    "    tokens = filter_allowed_chars(tokens)\n",
    "    tokens = filter_length(tokens)\n",
    "    tokens = filter_digits(tokens)\n",
    "\n",
    "    return tokens if tokens else None\n",
    "\n",
    "df_clean[\"url_path\"] = df_clean[\"url_path\"].apply(token_filter_pipeline)\n",
    "df_clean = df_clean.dropna(subset=[\"url_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ac8bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Token Filtering: (551714, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_host_registered_domain</th>\n",
       "      <th>url_path</th>\n",
       "      <th>fetch_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711011</th>\n",
       "      <td>nutriland.ro</td>\n",
       "      <td>[products]</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100122</th>\n",
       "      <td>tunetanken.ro</td>\n",
       "      <td>[categorie, agro, steps]</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834381</th>\n",
       "      <td>protv.ro</td>\n",
       "      <td>[emisiuni, episodul]</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270277</th>\n",
       "      <td>epson.ro</td>\n",
       "      <td>[ro_ro, produse, op%c8%9biuni, standard, p, 10...</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25368</th>\n",
       "      <td>buhnici.ro</td>\n",
       "      <td>[tag]</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        url_host_registered_domain  \\\n",
       "711011                nutriland.ro   \n",
       "1100122              tunetanken.ro   \n",
       "834381                    protv.ro   \n",
       "270277                    epson.ro   \n",
       "25368                   buhnici.ro   \n",
       "\n",
       "                                                  url_path  fetch_status  \n",
       "711011                                          [products]           302  \n",
       "1100122                           [categorie, agro, steps]           503  \n",
       "834381                                [emisiuni, episodul]           403  \n",
       "270277   [ro_ro, produse, op%c8%9biuni, standard, p, 10...           301  \n",
       "25368                                                [tag]           301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample of the data\n",
    "print(f\"Local Token Filtering: {df_clean.shape}\")\n",
    "display(df_clean.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bbf8db",
   "metadata": {},
   "source": [
    "## Global Token Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278873e",
   "metadata": {},
   "source": [
    "This step is done separately as it requires calculating global statistics across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b496b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_clean.groupby(\"url_host_registered_domain\")[\"url_path\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec063868",
   "metadata": {},
   "source": [
    "This is one of the most effective ways to reduce noise in the dataset. By removing infrequent tokens, we can focus the model on more relevant and common directory names, improving its predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad6744ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409086, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create global frequency counter\n",
    "global_freqs = Counter(token for tokens in df_grouped[\"url_path\"] for token in set(tokens))\n",
    "\n",
    "# Remove infrequent tokens\n",
    "def filter_by_min_domains(tokens, global_freqs, min_domains=10):\n",
    "    filtered_tokens = [t for t in tokens if global_freqs.get(t, 0) >= min_domains]\n",
    "\n",
    "    return filtered_tokens if filtered_tokens else None\n",
    "\n",
    "# Apply changes using a pipeline\n",
    "df_clean[\"url_path\"] = df_clean[\"url_path\"].apply(lambda tokens: filter_by_min_domains(tokens, global_freqs))\n",
    "\n",
    "# Remove rows with empty url_path after filtering\n",
    "df_clean = df_clean.dropna(subset=[\"url_path\"])\n",
    "\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189819e8",
   "metadata": {},
   "source": [
    "This drastically reduces the vocabulary size, which can improve the efficiency of the model used for lateral directory prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bc24581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045851\n",
      "631971\n"
     ]
    }
   ],
   "source": [
    "# Display how many tokens were removed\n",
    "print(df_grouped[\"url_path\"].apply(len).sum())\n",
    "print(df_clean[\"url_path\"].apply(len).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f16151",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636a79e",
   "metadata": {},
   "source": [
    "**Herarchical model**\n",
    "\n",
    "LSTM was chosen due to its effectiveness in handling sequential data, such as directory paths.\n",
    "\n",
    "**Lateral model**\n",
    "\n",
    "Co-occurrence-based recommender system was selected for its ability to suggest directories based on their occurrence patterns across different websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374a893",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1aba887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 16:59:38.963278: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-26 16:59:39.497627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-26 16:59:42.031176: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095bc9de",
   "metadata": {},
   "source": [
    "## Lateral Directory Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ba254",
   "metadata": {},
   "source": [
    "From the preprocessed data, we will take only the top-level directories for training the lateral directory prediction model. Then, each token will be grouped by its registered domain to create a list of unique top-level directories for each website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c72f29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tagged'}, {'author', 'home'}, {'2022'}, {'blog', 'tag', 'register'}, {'artist'}, {'2019', '2016', '2021', '2017', '2018', '2015', '2020'}, {'ro_ro'}, {'blog', 'pages'}, {'page'}, {'category'}]\n"
     ]
    }
   ],
   "source": [
    "df_clean_grouped = df_clean.copy()\n",
    "df_clean_grouped[\"first_path\"] = df_clean_grouped[\"url_path\"].str[0]\n",
    "df_clean_grouped = df_clean_grouped.drop(columns=[\"url_path\", \"fetch_status\"])\n",
    "df_clean_grouped = df_clean_grouped.groupby(\"url_host_registered_domain\")[\"first_path\"].apply(set).reset_index()\n",
    "df_clean_grouped = df_clean_grouped[\"first_path\"].tolist()\n",
    "\n",
    "print(df_clean_grouped[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6780f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n"
     ]
    }
   ],
   "source": [
    "# Number of unique dir names\n",
    "unique_dirs = {d for sublist in df_clean_grouped for d in sublist}\n",
    "print(len(unique_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e36060",
   "metadata": {},
   "source": [
    "The co-occurrence matrix is built by counting how often each pair of directories appears together across different websites. This matrix serves as the foundation for the recommendation system. Then, for a given set of existing directories on a website, the model can recommend additional directories that frequently co-occur with them based on the co-occurrence matrix. The `top-k` parameter can be adjusted to control how many recommendations are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ad0c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 1,563 directories\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Build index\n",
    "cooccur = defaultdict(Counter)\n",
    "dir_counts = Counter()\n",
    "\n",
    "for site in df_clean_grouped:\n",
    "    dirs = list(set(site))\n",
    "    dir_counts.update(dirs)\n",
    "    for i, d1 in enumerate(dirs):\n",
    "        for d2 in dirs[i+1:]:\n",
    "            cooccur[d1][d2] += 1\n",
    "            cooccur[d2][d1] += 1\n",
    "\n",
    "print(f\"Indexed {len(dir_counts):,} directories\")\n",
    "\n",
    "# Recommend\n",
    "def recommend(input_dirs, top_k=100):\n",
    "    scores = Counter()\n",
    "    for d in input_dirs:\n",
    "        for related, count in cooccur[d].most_common(top_k * 2):\n",
    "            if related not in input_dirs:\n",
    "                scores[related] += count\n",
    "    return scores.most_common(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef90ad",
   "metadata": {},
   "source": [
    "## Herarchical Directory Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e811c1f",
   "metadata": {},
   "source": [
    "The steps to train the hierarchical model using LSTM are as follows:\n",
    "1. **Data Preparation**: The preprocessed directory paths are tokenized and converted into sequences of integers. Each sequence represents a path, with each token corresponding to a directory name.\n",
    "2. **Model Architecture**: An LSTM model is designed with an embedding layer to convert tokens into dense vectors.\n",
    "3. **Training**: The model is trained using the prepared sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e186e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dntx/.pyenv/versions/tfenv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-10-26 16:59:45.333236: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm (\u001b[38;5;33mLSTM\u001b[0m)                      ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 4.4097\n",
      "Epoch 2/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.8826\n",
      "Epoch 3/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.7580\n",
      "Epoch 4/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.6737\n",
      "Epoch 5/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.5925\n",
      "Epoch 6/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.4974\n",
      "Epoch 7/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.3801\n",
      "Epoch 8/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.2608\n",
      "Epoch 9/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.1511\n",
      "Epoch 10/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.0503\n",
      "Epoch 11/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.9515\n",
      "Epoch 12/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.8540\n",
      "Epoch 13/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.7596\n",
      "Epoch 14/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.6658\n",
      "Epoch 15/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.5756\n",
      "Epoch 16/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.4915\n",
      "Epoch 17/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.4095\n",
      "Epoch 18/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.3352\n",
      "Epoch 19/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.2650\n",
      "Epoch 20/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.1976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f951b803ce0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to 10,000\n",
    "tokenized_paths = df_clean[\"url_path\"].tolist()[:10000]\n",
    "\n",
    "# Flatten all tokens\n",
    "all_tokens = list(set(chain.from_iterable(tokenized_paths)))\n",
    "\n",
    "# Assign indices\n",
    "token_to_idx = {\n",
    "    token: idx + 1 for idx, token in enumerate(all_tokens)\n",
    "}\n",
    "\n",
    "# Reverse mapping\n",
    "idx_to_token = {idx: token for token, idx in token_to_idx.items()}\n",
    "\n",
    "# Get vocab size\n",
    "vocab_size = len(token_to_idx) + 1\n",
    "\n",
    "# Prepare input and target sequences\n",
    "input_seqs = []\n",
    "target_tokens = []\n",
    "\n",
    "# Build sequences\n",
    "for path in tokenized_paths:\n",
    "    for i in range(1, len(path)):\n",
    "        prefix = [token_to_idx[t] for t in path[:i]]\n",
    "        target = token_to_idx[path[i]]\n",
    "        input_seqs.append(prefix)\n",
    "        target_tokens.append(target)\n",
    "\n",
    "max_len = max(len(seq) for seq in input_seqs)\n",
    "\n",
    "# Pad sequences\n",
    "X = pad_sequences(input_seqs, maxlen=max_len, padding=\"pre\")\n",
    "\n",
    "# Target array\n",
    "y = np.array(target_tokens)\n",
    "\n",
    "# Build model\n",
    "model = Sequential(\n",
    "    [\n",
    "        # Embedding layer\n",
    "        Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len),\n",
    "        # LSTM layer\n",
    "        LSTM(64),\n",
    "        # Output layer\n",
    "        Dense(vocab_size, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile and summarize\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# Helper to detect numeric tokens\n",
    "def is_numeric(token):\n",
    "    return re.fullmatch(r\"\\d+\", token) is not None\n",
    "\n",
    "# Build sample weights based on target token type\n",
    "sample_weights = np.array([\n",
    "    0.1 if is_numeric(idx_to_token[t]) else 1.0\n",
    "    for t in y\n",
    "])\n",
    "\n",
    "# Train the model with sample weights\n",
    "model.fit(X, y, epochs=20, batch_size=32, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304a766",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafc818",
   "metadata": {},
   "source": [
    "## Herarchical Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d407b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attachment', 'products', 'bilete', 'search', 'product', 'category', 'stiri', 'details', 'news', 'produs', 'page', 'node', 'p', 'cart', 'educatie', 'bucuresti', 'home', 'ro', 'tickets', 'produse', 'articol', 'pages', 'special', 'timisoara', 'oferta', 'artist', 'frumusete', 'articole', 'content', 'wishlist', 'iasi', 'c', 'ten', 'activitate', 'store', 'blog', 'fara-categorie', 'google', 'filtre', 'games', 'literatura', 'valcea', 'author', 'tag', 'tags', 'cercetare', 'national', 'wellness', 'collections', 'contact']\n"
     ]
    }
   ],
   "source": [
    "def predict_lateral_tf(model, input_path, top_k=50):\n",
    "    tokens = [token_to_idx[t] for t in input_path if t in token_to_idx]\n",
    "    padded = pad_sequences([tokens], maxlen=max_len, padding=\"pre\")\n",
    "    probs = model.predict(padded, verbose=0)[0]\n",
    "    top_idx = probs.argsort()[-top_k:][::-1]\n",
    "    return [idx_to_token[i] for i in top_idx]\n",
    "\n",
    "\n",
    "input_path = [\"admin\"]\n",
    "suggestions = predict_lateral_tf(model, input_path)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b9ff8",
   "metadata": {},
   "source": [
    "## Lateral Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f423054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 20), ('course', 20), ('wp-content', 13), ('ro', 11), ('anunturi', 10), ('search', 9), ('files', 9), ('tag', 8), ('calendar', 8), ('author', 8), ('issue', 8), ('studenti', 8), ('pdf', 7), ('node', 7), ('category', 7), ('proiecte', 6), ('blog', 6), ('login', 6), ('2018', 6), ('article', 6), ('admitere', 6), ('component', 6), ('docs', 6), ('contact', 5), ('2021', 5), ('page', 5), ('evenimente', 5), ('fr', 5), ('documente', 5), ('mod', 5), ('content', 5), ('account', 5), ('2017', 5), ('2015', 5), ('cercetare', 5), ('de', 4), ('2023', 4), ('2019', 4), ('educatie', 4), ('imobiliare', 4), ('logout', 4), ('stiri', 4), ('departamente', 4), ('2022', 4), ('2016', 4), ('news', 3), ('documents', 3), ('2024', 3), ('despre-noi', 3), ('hu', 3), ('noutati', 3), ('cursuri', 3), ('arhiva', 3), ('forum', 3), ('media', 3), ('afaceri', 3), ('bucuresti', 3), ('2', 3), ('-', 3), ('frontend', 3), ('about', 3), ('2025', 3), ('publicatii', 3), ('organizare', 3), ('pages', 3), ('images', 3), ('site', 3), ('masterat', 3), ('uploads', 2), ('1', 2), ('event', 2), ('oferte', 2), ('profil', 2), ('web', 2), ('cariera', 2), ('api', 2), ('international', 2), ('help', 2), ('articole', 2), ('companii', 2), ('public', 2), ('personal', 2), ('lifestyle', 2), ('eveniment', 2), ('hc', 2), ('topic', 2), ('agricultura', 2), ('auto', 2), ('locuri-de-munca', 2), ('promotii', 2), ('neamt', 2), ('suceava', 2), ('cluj', 2), ('prahova', 2), ('sites', 2), ('main', 2), ('pagini', 2), ('altele', 2), ('despre', 2), ('store', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(recommend(['admin', 'user'], 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 (TF)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
